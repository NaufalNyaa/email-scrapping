===============================================================================
                    TIPS PENGGUNAAN EMAIL SCRAPER ADVANCED v2.0
                          NaufalNyaa x MbullHexWorld
===============================================================================

üìã DAFTAR ISI
=============
1. Tips Dasar Penggunaan
2. Pengaturan Parameter Optimal
3. Strategi Berdasarkan Jenis Website
4. Troubleshooting Umum
5. Best Practices
6. Contoh Command Lengkap
7. Interpretasi Hasil
8. Penggunaan Etis

===============================================================================

üöÄ 1. TIPS DASAR PENGGUNAAN
===========================

A. PERSIAPAN AWAL
-----------------
‚Ä¢ Pastikan koneksi internet stabil
‚Ä¢ Install semua dependencies: pip install -r requirements.txt
‚Ä¢ Test dengan website kecil dulu sebelum target besar
‚Ä¢ Siapkan folder khusus untuk hasil scraping

B. MEMILIH MODE YANG TEPAT
--------------------------
‚Ä¢ Mode Interaktif: Untuk pemula atau testing
  Command: python mail_advanced.py

‚Ä¢ Mode Command Line: Untuk automation atau advanced user
  Command: python mail_advanced.py -u https://target.com [options]

C. VALIDASI URL TARGET
----------------------
‚Ä¢ Selalu gunakan https:// atau http://
‚Ä¢ Test buka URL di browser dulu
‚Ä¢ Pastikan website dapat diakses
‚Ä¢ Cek apakah ada halaman contact/about yang berisi email

===============================================================================

‚öôÔ∏è 2. PENGATURAN PARAMETER OPTIMAL
===================================

A. DEPTH (KEDALAMAN CRAWLING)
-----------------------------
‚Ä¢ Website Kecil (< 100 halaman): depth 2-3
‚Ä¢ Website Medium (100-1000 halaman): depth 3-4
‚Ä¢ Website Besar (> 1000 halaman): depth 4-6
‚Ä¢ Universitas/Institusi: depth 5-7

B. THREADS (JUMLAH THREAD)
--------------------------
‚Ä¢ Koneksi Lambat: 3-5 threads
‚Ä¢ Koneksi Normal: 5-8 threads
‚Ä¢ Koneksi Cepat: 8-12 threads
‚Ä¢ Server Powerful: 10-15 threads
‚Ä¢ JANGAN > 20 threads (bisa banned)

C. DELAY SETTINGS
-----------------
‚Ä¢ Website Friendly: 1-2 detik
‚Ä¢ Website Normal: 2-3 detik
‚Ä¢ Website Strict: 3-5 detik
‚Ä¢ Website dengan Anti-Bot: 5-10 detik

D. OUTPUT FORMATS
-----------------
‚Ä¢ Untuk Analisis: json, xlsx
‚Ä¢ Untuk Import: csv
‚Ä¢ Untuk Dokumentasi: txt
‚Ä¢ Untuk Semua: txt,csv,json,xlsx

===============================================================================

üéØ 3. STRATEGI BERDASARKAN JENIS WEBSITE
=========================================

A. WEBSITE UNIVERSITAS/SEKOLAH
-------------------------------
Command Optimal:
python mail_advanced.py -u https://university.edu -d 5 -t 8 --delay-min 2 --delay-max 4 -o txt,csv,xlsx

Tips:
‚Ä¢ Focus pada halaman: /faculty, /staff, /contact, /directory
‚Ä¢ Gunakan depth tinggi (5-6)
‚Ä¢ Delay sedang (2-4 detik)
‚Ä¢ Biasanya banyak email di subdomain

B. WEBSITE PERUSAHAAN
---------------------
Command Optimal:
python mail_advanced.py -u https://company.com -d 4 -t 6 --delay-min 1 --delay-max 3 -o csv,json

Tips:
‚Ä¢ Focus pada: /about, /team, /contact, /careers
‚Ä¢ Depth medium (3-4)
‚Ä¢ Threads sedang (5-8)
‚Ä¢ Sering ada email di press release

C. WEBSITE PEMERINTAH
---------------------
Command Optimal:
python mail_advanced.py -u https://gov-site.go.id -d 6 -t 5 --delay-min 3 --delay-max 5 --no-robots -o txt,xlsx

Tips:
‚Ä¢ Gunakan delay tinggi (3-5 detik)
‚Ä¢ Depth tinggi untuk struktur kompleks
‚Ä¢ Sering perlu --no-robots
‚Ä¢ Banyak email di direktori pegawai

D. WEBSITE E-COMMERCE
---------------------
Command Optimal:
python mail_advanced.py -u https://shop.com -d 3 -t 10 --cloudflare --delay-min 2 -o csv

Tips:
‚Ä¢ Sering pakai Cloudflare (gunakan --cloudflare)
‚Ä¢ Email biasanya di: /contact, /support, /about
‚Ä¢ Depth rendah cukup (2-3)
‚Ä¢ Threads tinggi OK

E. WEBSITE BERITA/MEDIA
-----------------------
Command Optimal:
python mail_advanced.py -u https://news.com -d 4 -t 8 --delay-min 1 --delay-max 2 -o json,xlsx

Tips:
‚Ä¢ Banyak email di halaman author/journalist
‚Ä¢ Struktur artikel bisa dalam
‚Ä¢ Email di footer dan contact page
‚Ä¢ Biasanya server kuat, delay bisa rendah

===============================================================================

üîß 4. TROUBLESHOOTING UMUM
===========================

A. ERROR "CONNECTION TIMEOUT"
-----------------------------
Solusi:
‚Ä¢ Kurangi jumlah threads: -t 3
‚Ä¢ Tambah delay: --delay-min 3 --delay-max 5
‚Ä¢ Cek koneksi internet
‚Ä¢ Coba gunakan --cloudflare

B. ERROR "403 FORBIDDEN"
------------------------
Solusi:
‚Ä¢ Gunakan --cloudflare
‚Ä¢ Tambah delay lebih besar
‚Ä¢ Kurangi threads
‚Ä¢ Coba --no-robots

C. ERROR "TOO MANY REQUESTS"
----------------------------
Solusi:
‚Ä¢ Kurangi threads drastis: -t 2
‚Ä¢ Tambah delay: --delay-min 5 --delay-max 10
‚Ä¢ Tunggu beberapa menit, coba lagi
‚Ä¢ Ganti IP/VPN

D. HASIL EMAIL SEDIKIT
----------------------
Solusi:
‚Ä¢ Tambah depth: -d 6
‚Ä¢ Gunakan --allow-external
‚Ä¢ Cek manual apakah website memang punya email
‚Ä¢ Coba target URL yang lebih spesifik

E. PROSES TERLALU LAMBAT
------------------------
Solusi:
‚Ä¢ Tambah threads: -t 10
‚Ä¢ Kurangi delay: --delay-min 0.5 --delay-max 1
‚Ä¢ Kurangi depth jika tidak perlu
‚Ä¢ Pastikan koneksi internet stabil

===============================================================================

‚úÖ 5. BEST PRACTICES
=====================

A. SEBELUM SCRAPING
-------------------
‚Ä¢ Baca robots.txt website: https://target.com/robots.txt
‚Ä¢ Cek terms of service website
‚Ä¢ Test dengan sample kecil dulu
‚Ä¢ Backup command yang berhasil

B. SAAT SCRAPING
-----------------
‚Ä¢ Monitor progress bar dan statistik
‚Ä¢ Jangan interrupt di tengah jalan
‚Ä¢ Catat command yang digunakan
‚Ä¢ Monitor penggunaan bandwidth

C. SETELAH SCRAPING
-------------------
‚Ä¢ Backup hasil ke multiple format
‚Ä¢ Validasi email yang ditemukan
‚Ä¢ Dokumentasikan sumber dan tanggal
‚Ä¢ Clean up duplicate emails

D. ETIKA SCRAPING
-----------------
‚Ä¢ Gunakan delay yang wajar (min 1 detik)
‚Ä¢ Jangan overwhelm server target
‚Ä¢ Hormati robots.txt kecuali perlu
‚Ä¢ Gunakan untuk tujuan legitimate
‚Ä¢ Jangan scraping data personal sensitif

===============================================================================

üí° 6. CONTOH COMMAND LENGKAP
=============================

A. SCRAPING CEPAT (TESTING)
----------------------------
python mail_advanced.py -u https://example.com -d 2 -t 3 --delay-min 1 -o txt

B. SCRAPING STANDARD
---------------------
python mail_advanced.py -u https://university.edu -d 4 -t 6 --delay-min 2 --delay-max 3 -o txt,csv

C. SCRAPING COMPREHENSIVE
-------------------------
python mail_advanced.py -u https://target.com -d 6 -t 8 --delay-min 2 --delay-max 4 -o txt,csv,json,xlsx --output-dir results/

D. SCRAPING ANTI-BOT WEBSITE
-----------------------------
python mail_advanced.py -u https://protected.com --cloudflare --delay-min 3 --delay-max 5 -t 3 --no-robots -o json

E. SCRAPING EXTERNAL DOMAINS
-----------------------------
python mail_advanced.py -u https://main-site.com --allow-external -d 5 -t 5 --delay-min 2 -o csv,xlsx

F. SCRAPING DENGAN VERBOSE
---------------------------
python mail_advanced.py -u https://target.com -d 4 -t 6 --verbose -o txt,json

===============================================================================

üìä 7. INTERPRETASI HASIL
=========================

A. STATISTIK YANG BAIK
-----------------------
‚Ä¢ Success Rate > 90% (pages_visited vs pages_failed)
‚Ä¢ Email/Page Ratio > 0.1 (minimal 1 email per 10 halaman)
‚Ä¢ Duration reasonable (tidak terlalu lama)
‚Ä¢ Queue kosong di akhir (semua link terproses)

B. TANDA HASIL OPTIMAL
-----------------------
‚Ä¢ Banyak email dengan multiple sources
‚Ä¢ Variasi domain email (tidak semua sama)
‚Ä¢ Email dari halaman berbeda-beda
‚Ä¢ Tidak ada error "blocked" atau "forbidden"

C. RED FLAGS
------------
‚Ä¢ Terlalu banyak pages_failed
‚Ä¢ Semua email dari 1-2 halaman saja
‚Ä¢ Banyak email invalid/spam
‚Ä¢ Proses terhenti di tengah

D. VALIDASI HASIL
-----------------
‚Ä¢ Cek sample email secara manual
‚Ä¢ Pastikan email format valid
‚Ä¢ Remove duplicate manual jika perlu
‚Ä¢ Cross-check dengan website langsung

===============================================================================

‚öñÔ∏è 8. PENGGUNAAN ETIS
======================

A. DO's (LAKUKAN)
-----------------
‚úÖ Gunakan delay minimal 1 detik
‚úÖ Hormati robots.txt
‚úÖ Limit threads (max 15)
‚úÖ Scraping untuk research/business legitimate
‚úÖ Dokumentasikan sumber data
‚úÖ Respect website terms of service
‚úÖ Test dengan sample kecil dulu
‚úÖ Monitor server load impact

B. DON'Ts (JANGAN)
------------------
‚ùå Scraping untuk spam/phishing
‚ùå Overwhelm server dengan request berlebihan
‚ùå Ignore robots.txt tanpa alasan kuat
‚ùå Scraping data personal sensitif
‚ùå Jual/share email tanpa consent
‚ùå Scraping competitor untuk sabotase
‚ùå Bypass security untuk akses illegal
‚ùå Scraping website yang explicitly forbid

C. LEGAL CONSIDERATIONS
-----------------------
‚Ä¢ Cek local laws tentang data scraping
‚Ä¢ Pastikan comply dengan GDPR jika applicable
‚Ä¢ Respect copyright dan intellectual property
‚Ä¢ Gunakan data sesuai intended purpose
‚Ä¢ Consider opt-out mechanisms

===============================================================================

üìû SUPPORT & TROUBLESHOOTING
=============================

Jika mengalami masalah:
1. Cek dokumentasi README_advanced.md
2. Test dengan website sederhana dulu
3. Coba kurangi parameter (threads, depth)
4. Pastikan dependencies terinstall lengkap
5. Cek koneksi internet dan firewall

Developed by: NaufalNyaa x MbullHexWorld
Version: 2.0
Last Updated: 2024

===============================================================================
                              END OF DOCUMENT
===============================================================================